# -*- coding: utf-8 -*-
# app.py â€” Integrated Streamlit app
# - Friendly intro for beginners (Korean)
# - Representative portfolio presets (60:40, All Weather, GAA) with descriptions + pie
# - Sidebar editor shows "ì¶”ì¢…ì§€ìˆ˜(ìë™)" without "ì•Œ ìˆ˜ ì—†ìŒ" spam
# - Auto audit & proxy mapping for ETFs (incl. IAU, BCI)
# - Hybrid backfill: preâ€‘listing period uses proxy; postâ€‘listing uses ETF
# - Simple backtest: portfolio index, CAGR/Vol/MDD

from __future__ import annotations
import os
import io
import math
import json
import re
from dataclasses import dataclass, asdict
from typing import Dict, List, Optional, Tuple
from datetime import datetime, date

import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

# Optional: Korean font for matplotlib (bestâ€‘effort)
try:
    from matplotlib import font_manager, rcParams
    # Common paths on Linux/Windows. Add your own if needed.
    CANDIDATES = [
        "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
        "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
        "C:/Windows/Fonts/malgun.ttf",
    ]
    for p in CANDIDATES:
        if os.path.exists(p):
            font_manager.fontManager.addfont(p)
            rcParams["font.family"] = font_manager.FontProperties(fname=p).get_name()
            break
    rcParams["axes.unicode_minus"] = False
except Exception:
    pass

# -----------------------------
# Page Config
# -----------------------------
st.set_page_config(page_title="ETF Backfill Portfolio Visualizer", layout="wide")

# =============================
# Data & Mapping Layer
# =============================
@dataclass
class ProxySpec:
    source: str   # "YF"(Yahoo) | "FRED"(not used directly in loader here)
    series: str   # Yahoo symbol (preferred in this app)
    name: str
    transform: str = "identity"

# Base proxy map â€” include troublesome ones (IAU/BCI) mapped to Yahooâ€‘loadable proxies
BASE_PROXY_MAP: Dict[str, ProxySpec] = {
    # Stocks / Bonds examples
    "QQQ":  ProxySpec("YF", "^NDX", "NASDAQâ€‘100 Index"),   # Use index symbol for longer history
    "SPY":  ProxySpec("YF", "^GSPC", "S&P 500 Index"),
    "VTI":  ProxySpec("YF", "VTI", "Total U.S. Stock (ETF proxy)"),
    "VEA":  ProxySpec("YF", "VEA", "Dev exâ€‘US (ETF proxy)"),
    "VWO":  ProxySpec("YF", "VWO", "EM Equities (ETF proxy)"),
    "VNQ":  ProxySpec("YF", "VNQ", "U.S. REITs (ETF proxy)"),
    "IEF":  ProxySpec("YF", "IEF", "U.S. Treasury 7â€‘10y (ETF proxy)"),
    "VGLT": ProxySpec("YF", "VGLT", "U.S. Treasury Long (ETF proxy)"),
    "BND":  ProxySpec("YF", "AGG", "U.S. Aggregate (AGG as proxy)"),
    "AGG":  ProxySpec("YF", "AGG", "U.S. Aggregate Bonds"),
    "BIL":  ProxySpec("YF", "BIL", "1â€‘3M Tâ€‘Bill"),
    # Commodities & Gold â€” the troublemakers
    "IAU":  ProxySpec("YF", "GLD",     "Gold proxy via GLD"),
    "GLD":  ProxySpec("YF", "GLD",     "Gold proxy via GLD"),
    "IAU.M":ProxySpec("YF", "GLD",     "Gold proxy via GLD"),
    "IAUUSD":ProxySpec("YF", "XAUUSD=X","Spot Gold USD"),
    "DBC":  ProxySpec("YF", "DBC",     "Broad Commodities (ETF)"),
    "BCI":  ProxySpec("YF", "^SPGSCI", "S&P GSCI Index (broad commodity)"),
}

# Lightweight yfinance helpers
@st.cache_data(show_spinner=False)
def yf_download(symbol: str, start: str = "1970-01-01", end: Optional[str] = None, auto_adjust: bool = True) -> pd.Series:
    import yfinance as yf
    df = yf.download(symbol, start=start, end=end, progress=False, auto_adjust=auto_adjust)
    if df.empty:
        return pd.Series(dtype=float, name=symbol)
    # Prefer Adj Close if present
    col = "Adj Close" if "Adj Close" in df.columns else "Close"
    s = df[col].dropna()
    s.name = symbol
    return s

@st.cache_data(show_spinner=False)
def yf_info(ticker: str) -> dict:
    try:
        import yfinance as yf
        t = yf.Ticker(ticker)
        info = t.info or {}
        return {
            "longName": info.get("longName"),
            "shortName": info.get("shortName"),
            "underlyingIndex": info.get("underlyingIndex"),
            "category": info.get("category"),
            "fundFamily": info.get("fundFamily"),
        }
    except Exception:
        return {}

# Rules to guess proxies from metadata text
_RULES: List[Tuple[re.Pattern, ProxySpec]] = [
    (re.compile(r"gold|ê¸ˆ", re.I), ProxySpec("YF", "GLD", "Gold proxy via GLD")),
    (re.compile(r"commodity|ì›ìì¬|gsci|bcom", re.I), ProxySpec("YF", "^SPGSCI", "S&P GSCI Index")),
    (re.compile(r"nasdaq.*100", re.I), ProxySpec("YF", "^NDX", "NASDAQâ€‘100")),
    (re.compile(r"s&p.*500|sp\s*500", re.I), ProxySpec("YF", "^GSPC", "S&P 500")),
    (re.compile(r"7\-10|intermediate.*treasury|ì¤‘ê¸°êµ­ì±„", re.I), ProxySpec("YF", "IEF", "U.S. Treasury 7â€‘10y")),
    (re.compile(r"tips|ë¬¼ê°€ì—°ë™", re.I), ProxySpec("YF", "TIP", "U.S. TIPS (ETF)")),
    (re.compile(r"reit|ë¦¬ì¸ ", re.I), ProxySpec("YF", "VNQ", "U.S. REITs (ETF)")),
]

@st.cache_data(show_spinner=False)
def audit_and_autofix_proxies(etfs: List[str], base_map: Dict[str, ProxySpec]) -> Tuple[pd.DataFrame, Dict[str, ProxySpec]]:
    pmap = dict(base_map)
    rows = []
    for t in etfs:
        key = t.upper().strip()
        if key in pmap:
            rows.append({"í‹°ì»¤": key, "ìƒíƒœ": "OK", "ì œì•ˆ": f"{pmap[key].source}:{pmap[key].series}"})
            continue
        info = yf_info(key)
        text = " ".join([str(v) for v in info.values() if v]).lower()
        suggestion = None
        for pat, spec in _RULES:
            if pat.search(text) or pat.search(key):
                suggestion = spec
                break
        if suggestion is not None:
            pmap[key] = suggestion
            rows.append({"í‹°ì»¤": key, "ìƒíƒœ": "AUTO_MAPPED", "ì œì•ˆ": f"{suggestion.source}:{suggestion.series}"})
        else:
            rows.append({"í‹°ì»¤": key, "ìƒíƒœ": "NEEDS_MANUAL", "ì œì•ˆ": "(ì—†ìŒ)"})
    return pd.DataFrame(rows), pmap

# Resolve a proxy ticker to load with Yahoo
def resolve_proxy_ticker(ticker: str, proxy_map: Dict[str, ProxySpec]) -> str:
    t = ticker.upper().strip()
    spec = proxy_map.get(t)
    if spec:
        return spec.series
    # fallbacks
    if t in {"IAU", "GLD"}: return "GLD"
    if t in {"BCI", "DBC"}: return "^SPGSCI"
    return ""

# Hybrid builder (ETF + Proxy splice)
def build_hybrid_series_from_proxy(etf_ticker: str, proxy_ticker: str, start: str = "1970-01-01") -> pd.Series:
    if not proxy_ticker:
        # Only ETF
        s_etf = yf_download(etf_ticker, start=start)
        s_etf.name = f"HYBRID_{etf_ticker}"
        return s_etf
    s_etf = yf_download(etf_ticker, start=start)
    s_proxy = yf_download(proxy_ticker, start=start)
    if s_etf.empty and s_proxy.empty:
        return pd.Series(dtype=float, name=f"HYBRID_{etf_ticker}")
    # businessâ€‘day index
    idx = pd.date_range(
        start=min([x.index.min() for x in [s_etf, s_proxy] if not x.empty]),
        end=max([x.index.max() for x in [s_etf, s_proxy] if not x.empty]),
        freq="B",
    )
    e = s_etf.reindex(idx).ffill()
    p = s_proxy.reindex(idx).ffill()
    # scale proxy to ETF over overlap
    overlap = pd.concat([e, p], axis=1).dropna()
    if overlap.empty:
        scaled_p = p
    else:
        x = overlap.iloc[:, 1].values
        y = overlap.iloc[:, 0].values
        a = float((x @ y) / (x @ x)) if np.isfinite((x @ y) / (x @ x)) else 1.0
        scaled_p = p * a
    # splice
    cutoff = e.first_valid_index()
    hybrid = scaled_p.copy()
    if cutoff is not None:
        hybrid.loc[cutoff:] = e.loc[cutoff:]
    hybrid.name = f"HYBRID_{etf_ticker}"
    return hybrid.dropna()

# Simple metrics
def to_monthly(s: pd.Series) -> pd.Series:
    return s.resample("M").last()

def perf_metrics(series: pd.Series) -> dict:
    if series.empty:
        return {"CAGR": np.nan, "Vol": np.nan, "MDD": np.nan}
    idx = series / series.iloc[0] * 100.0
    m = to_monthly(idx)
    rets = m.pct_change().dropna()
    # CAGR
    years = (m.index[-1] - m.index[0]).days / 365.25
    cagr = (m.iloc[-1] / m.iloc[0]) ** (1/years) - 1 if years > 0 else np.nan
    # Vol (annualized)
    vol = rets.std() * math.sqrt(12)
    # MDD
    roll_max = idx.cummax()
    dd = idx / roll_max - 1
    mdd = dd.min()
    return {"CAGR": cagr, "Vol": vol, "MDD": mdd}

# =============================
# UI â€” Intro & Presets
# =============================
import streamlit as st

# --- ì„¹ì…˜ ë Œë” í•¨ìˆ˜ ì˜ˆì‹œ (ì´ë¯¸ ìˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©) ---
def render_intro():
    st.markdown("### ì²˜ìŒ ì˜¤ì…¨ë‚˜ìš”?")
    st.write("- ì´ ì•±ì€ ETF/ì¸ë±ìŠ¤ í•˜ì´ë¸Œë¦¬ë“œ ë°±í…ŒìŠ¤íŠ¸ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.")
    st.write("- ì¢Œì¸¡ì—ì„œ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ì„¤ì •í•˜ê³  â€˜ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰â€™ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

def render_featured_portfolios():
    st.markdown("### ëŒ€í‘œ í¬íŠ¸í´ë¦¬ì˜¤ ë¹„êµ")
    st.write("ì˜ˆì‹œ í¬íŠ¸í´ë¦¬ì˜¤ë“¤ì„ ê°„ë‹¨íˆ ë¹„êµí•©ë‹ˆë‹¤.")

def render_inputs():
    st.markdown("### ë°±í…ŒìŠ¤íŠ¸ ì„¤ì •")
    # ğŸ‘‰ ì—¬ê¸°ì—” ê¸°ì¡´ ì…ë ¥ ìœ„ì ¯ë“¤ (í‹°ì»¤, ë¹„ì¤‘, ì‹œì‘/ì¢…ë£Œì¼, ë¦¬ë°¸ëŸ°ì‹± ë“±) ë°°ì¹˜
    # ì˜ˆì‹œ:
    # tickers = st.text_input("ETF í‹°ì»¤(ì‰¼í‘œë¡œ êµ¬ë¶„)", "QQQ,IEF")
    # weights = st.text_input("ë¹„ì¤‘(%)", "60,40")
    # start = st.date_input("ì‹œì‘ì¼", ...)
    # end = st.date_input("ì¢…ë£Œì¼", ...)
    # return dict(tickers=tickers, weights=weights, start=start, end=end)
    return {}

def run_backtest(params):
    # ğŸ‘‰ ì‹¤ì œ ë°±í…ŒìŠ¤íŠ¸ ë¡œì§ í˜¸ì¶œ
    # df, metrics, charts = ...
    # ì˜ˆì‹œ ê²°ê³¼ ë¦¬í„´
    return {
        "summary": {"CAGR": "8.4%", "MDD": "-17.2%", "Sharpe": "0.68"},
        "note": "ìƒ˜í”Œ ê²°ê³¼ì…ë‹ˆë‹¤. ì‹¤ì œ ë¡œì§ì— ì—°ê²°í•˜ì„¸ìš”."
    }

def render_results(result):
    st.markdown("## ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼")
    col1, col2, col3 = st.columns(3)
    col1.metric("CAGR", result["summary"]["CAGR"])
    col2.metric("MDD", result["summary"]["MDD"])
    col3.metric("Sharpe", result["summary"]["Sharpe"])
    st.caption(result.get("note", ""))

# --- ì—¬ê¸°ë¶€í„° ë©”ì¸ íë¦„ ---
def main():
    st.set_page_config(layout="wide")
    st.title("ETF ë°±í…ŒìŠ¤íŠ¸ í™•ì¥ ì›¹ì•±")

    # 1) ìƒíƒœ í”Œë˜ê·¸ ê¸°ë³¸ê°’
    if "backtest_started" not in st.session_state:
        st.session_state.backtest_started = False
    if "last_params" not in st.session_state:
        st.session_state.last_params = None
    if "last_result" not in st.session_state:
        st.session_state.last_result = None

    # 2) ì…ë ¥ í¼
    with st.form(key="bt_form", clear_on_submit=False):
        params = render_inputs()
        submitted = st.form_submit_button("ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰", use_container_width=True)

    # 3) ë²„íŠ¼ì„ ëˆ„ë¥´ë©´: í”Œë˜ê·¸ True + ê²°ê³¼ ê³„ì‚°
    if submitted:
        st.session_state.backtest_started = True
        st.session_state.last_params = params
        st.session_state.last_result = run_backtest(params)

    # 4) í”Œë˜ê·¸ì— ë”°ë¼ ì„¹ì…˜ í‘œì‹œ ìˆœì„œ/ê°€ì‹œì„± ì œì–´
    if st.session_state.backtest_started:
        # âœ… ê²°ê³¼ë¥¼ ìµœìƒë‹¨ì— ë¨¼ì € í‘œì‹œ
        render_results(st.session_state.last_result)

        # ì„ íƒ: ê²°ê³¼ í•˜ë‹¨ì— ì…ë ¥ ì„¹ì…˜(ì¬ì‹¤í–‰ìš©)ë§Œ ë…¸ì¶œ
        with st.expander("ì„¤ì • ë‹¤ì‹œ ì—´ê¸° / ì¬ì‹¤í–‰", expanded=False):
            with st.form(key="bt_form_again", clear_on_submit=False):
                params = render_inputs()
                re_submitted = st.form_submit_button("ë‹¤ì‹œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰", use_container_width=True)
            if re_submitted:
                st.session_state.last_params = params
                st.session_state.last_result = run_backtest(params)
                st.experimental_rerun()

        # ì„ íƒ: ì´ˆê¸°ì•ˆë‚´/ëŒ€í‘œí¬íŠ¸í´ë¦¬ì˜¤ í† ê¸€ ìŠ¤ìœ„ì¹˜(ê¸°ë³¸ì€ ìˆ¨ê¹€)
        st.toggle("ì´ˆê¸° ì•ˆë‚´/ëŒ€í‘œ í¬íŠ¸í´ë¦¬ì˜¤ ë³´ê¸°", value=False, key="show_guides")
        if st.session_state.show_guides:
            st.info("ì´ˆê¸° ì•ˆë‚´/ëŒ€í‘œ í¬íŠ¸í´ë¦¬ì˜¤ëŠ” ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í›„ ê¸°ë³¸ì ìœ¼ë¡œ ìˆ¨ê¹ë‹ˆë‹¤.")
            render_intro()
            render_featured_portfolios()

        # ë¦¬ì…‹ ë²„íŠ¼(ì™„ì „ ì´ˆê¸°í™”)
        if st.button("ì´ˆê¸°í™”(ì²˜ìŒ í™”ë©´ìœ¼ë¡œ)", type="secondary"):
            st.session_state.backtest_started = False
            st.session_state.last_params = None
            st.session_state.last_result = None
            st.experimental_rerun()

    else:
        # âœ… ì²˜ìŒ í™”ë©´(ì•„ì§ ì‹¤í–‰ ì „): ì•ˆë‚´ì™€ ëŒ€í‘œ í¬íŠ¸í´ë¦¬ì˜¤ ë…¸ì¶œ
        render_intro()
        render_featured_portfolios()

if __name__ == "__main__":
    main()

# =============================
# Sidebar â€” Portfolio Editor
# =============================
st.sidebar.header("1) í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±")

def _empty_rows(n=4):
    return pd.DataFrame({"í‹°ì»¤": ["" for _ in range(n)], "ë¹„ìœ¨ (%)": [0.0 for _ in range(n)]})

if "portfolio_rows" not in st.session_state:
    if "preset_portfolio" in st.session_state:
        p = st.session_state["preset_portfolio"]
        st.session_state["portfolio_rows"] = pd.DataFrame({
            "í‹°ì»¤": p.get("assets", []),
            "ë¹„ìœ¨ (%)": p.get("weights", []),
        })
    else:
        st.session_state["portfolio_rows"] = _empty_rows()

# Ensure a few empty rows for user convenience
base_df = st.session_state["portfolio_rows"]
if len(base_df) < 6:
    base_df = pd.concat([base_df, _empty_rows(6 - len(base_df))], ignore_index=True)

# Build auto mapping table from current tickers
def build_proxy_table_with_autofix(df_in: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, ProxySpec]]:
    tickers = [t for t in df_in["í‹°ì»¤"].astype(str).str.upper().str.strip().tolist() if t]
    report, pmap = audit_and_autofix_proxies(tickers, BASE_PROXY_MAP)
    rows = []
    for t in tickers:
        spec = pmap.get(t)
        label = "ì•Œ ìˆ˜ ì—†ìŒ"
        proxy = ""
        if spec:
            proxy = spec.series
            label = f"{spec.name} / proxy: {proxy}"
        elif t in {"IAU", "GLD"}:
            proxy = "GLD"; label = f"Gold proxy via GLD / proxy: {proxy}"
        elif t in {"BCI", "DBC"}:
            proxy = "^SPGSCI"; label = f"S&P GSCI Index / proxy: {proxy}"
        rows.append({"ETF": t, "Label": label, "Proxy": proxy})
    return pd.DataFrame(rows), pmap

proxy_table, proxy_map = build_proxy_table_with_autofix(base_df)

def _append_total_row(df: pd.DataFrame) -> pd.DataFrame:
    d = df.copy()
    total = float(pd.to_numeric(d["ë¹„ìœ¨ (%)"], errors="coerce").fillna(0).sum())
    d = pd.concat([d, pd.DataFrame({"í‹°ì»¤": ["í•©ê³„"], "ë¹„ìœ¨ (%)": [total]})], ignore_index=True)
    return d

editor_df = _append_total_row(base_df)

label_map = {r.ETF: r.Label for _, r in proxy_table.iterrows()}

def _label_for(t):
    t = str(t).upper().strip()
    if t == "í•©ê³„": return "â€”"
    return label_map.get(t, "ì•Œ ìˆ˜ ì—†ìŒ")

editor_df["ì¶”ì¢…ì§€ìˆ˜(ìë™)"] = editor_df["í‹°ì»¤"].apply(_label_for)

edited_df_out = st.sidebar.data_editor(
    editor_df,
    num_rows="dynamic",
    use_container_width=True,
    key="portfolio_editor",
    column_config={
        "í‹°ì»¤": st.column_config.TextColumn("í‹°ì»¤", help="ì˜ˆ: QQQ, IEF, IAU, BCI"),
        "ë¹„ìœ¨ (%)": st.column_config.NumberColumn("ë¹„ìœ¨ (%)", min_value=0.0, max_value=100.0, step=0.5, format="%.1f %%"),
        "ì¶”ì¢…ì§€ìˆ˜(ìë™)": st.column_config.TextColumn("ì¶”ì¢…ì§€ìˆ˜(ìë™)", help="ìë™ ë§¤í•‘ ë¼ë²¨", disabled=True),
    },
    disabled=["ì¶”ì¢…ì§€ìˆ˜(ìë™)"],
)

# Save back (drop total row)
st.session_state["portfolio_rows"] = edited_df_out.iloc[:-1][["í‹°ì»¤", "ë¹„ìœ¨ (%)"]]

st.sidebar.header("2) ê¸°ê°„ ì„¤ì •")
colA, colB = st.sidebar.columns(2)
with colA:
    start_date = st.date_input("ì‹œì‘ì¼", value=date(1990,1,1))
with colB:
    end_date = st.date_input("ì¢…ë£Œì¼", value=date.today())

run_bt = st.sidebar.button("ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰", type="primary")

# =============================
# Backtest Execution
# =============================
main_tab1, main_tab2 = st.tabs(["ğŸ“ˆ ê²°ê³¼", "ğŸ§ª ë§¤í•‘ ë¦¬í¬íŠ¸"])

if run_bt:
    with st.spinner("ë°ì´í„° ë¡œë”© ë° ë°±í…ŒìŠ¤íŠ¸ ì¤‘..."):
        dfp = st.session_state["portfolio_rows"].copy()
        # Clean rows
        dfp["í‹°ì»¤"] = dfp["í‹°ì»¤"].astype(str).str.upper().str.strip()
        dfp["ë¹„ìœ¨ (%)"] = pd.to_numeric(dfp["ë¹„ìœ¨ (%)"], errors="coerce").fillna(0.0)
        dfp = dfp[dfp["í‹°ì»¤"] != ""]
        dfp = dfp[dfp["ë¹„ìœ¨ (%)"] > 0]
        if dfp.empty:
            st.error("í¬íŠ¸í´ë¦¬ì˜¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. í‹°ì»¤ì™€ ë¹„ì¤‘ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            weights = dfp["ë¹„ìœ¨ (%)"].values
            if weights.sum() == 0:
                st.error("ë¹„ì¤‘ í•©ê³„ê°€ 0ì…ë‹ˆë‹¤. ë¹„ì¤‘ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                weights = weights / weights.sum()
                # Build each hybrid series
                series_map = {}
                for t, w in zip(dfp["í‹°ì»¤"].tolist(), weights.tolist()):
                    proxy_sym = resolve_proxy_ticker(t, proxy_map)
                    hy = build_hybrid_series_from_proxy(t, proxy_sym, start=start_date.isoformat())
                    series_map[t] = hy
                # Align & combine
                all_idx = None
                for s in series_map.values():
                    if all_idx is None:
                        all_idx = s.index
                    else:
                        all_idx = all_idx.union(s.index)
                all_idx = pd.DatetimeIndex(sorted(all_idx))
                rets = []
                for t, w in zip(dfp["í‹°ì»¤"].tolist(), weights.tolist()):
                    s = series_map[t].reindex(all_idx).ffill()
                    s = s / s.iloc[0] * 100.0
                    rets.append(s * w)
                port = pd.concat(rets, axis=1).sum(axis=1).dropna()
                port = port.loc[(port.index >= pd.to_datetime(start_date)) & (port.index <= pd.to_datetime(end_date))]
                # Plot
                with main_tab1:
                    st.subheader("í¬íŠ¸í´ë¦¬ì˜¤ ì§€ìˆ˜ (=100 ê¸°ì¤€)")
                    st.line_chart(port)
                    m = perf_metrics(port)
                    st.markdown(
                        f"**CAGR:** {m['CAGR']*100:,.2f}%  |  **ë³€ë™ì„±:** {m['Vol']*100:,.2f}%  |  **ìµœëŒ€ë‚™í­:** {m['MDD']*100:,.2f}%"
                    )

    with main_tab2:
        rep, _ = audit_and_autofix_proxies(dfp["í‹°ì»¤"].tolist(), BASE_PROXY_MAP)
        st.dataframe(rep, use_container_width=True)
else:
    with main_tab1:
        st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ì…ë ¥í•˜ê³  'ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰'ì„ ëˆŒëŸ¬ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    with main_tab2:
        st.dataframe(proxy_table, use_container_width=True)

st.markdown("---")
st.caption("â“˜ ì°¸ê³ : IAU/BCI ë“± ì¼ë¶€ ETFëŠ” ê³µì‹ 'ì§€ìˆ˜'ê°€ ê³µê°œ í‘œì¤€í™”ë˜ì–´ ìˆì§€ ì•Šì•„, Yahooì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œ ëŒ€ì²´ í”„ë¡ì‹œ(GLD, ^SPGSCI ë“±)ë¡œ ìë™ ë§¤í•‘í•©ë‹ˆë‹¤. ë” ì •êµí•œ ì§€ìˆ˜(ì˜ˆ: BCOMTR)ë¥¼ ì“°ë ¤ë©´ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")

