# -*- coding: utf-8 -*-
# app.py â€” Integrated Streamlit app (result-first after backtest)
# - Result-first UX: after "ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰", results appear at top and intro/presets are hidden
# - Friendly intro for beginners (Korean)  â€» shown only before the first run or if toggled
# - Representative portfolio presets (60:40, All Weather, GAA)
# - Sidebar editor shows "ì¶”ì¢…ì§€ìˆ˜(ìë™)" without "ì•Œ ìˆ˜ ì—†ìŒ" spam
# - Auto audit & proxy mapping for ETFs (incl. IAU, BCI)
# - Hybrid backfill: pre-listing period uses proxy; post-listing uses ETF
# - Simple backtest: portfolio index, CAGR/Vol/MDD

from __future__ import annotations
import os
import math
import re
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple
from datetime import date

import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

# Optional: Korean font for matplotlib (best-effort)
try:
    from matplotlib import font_manager, rcParams
    CANDIDATES = [
        "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
        "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
        "C:/Windows/Fonts/malgun.ttf",
    ]
    for p in CANDIDATES:
        if os.path.exists(p):
            font_manager.fontManager.addfont(p)
            rcParams["font.family"] = font_manager.FontProperties(fname=p).get_name()
            break
    rcParams["axes.unicode_minus"] = False
except Exception:
    pass

# -----------------------------
# Page Config
# -----------------------------
st.set_page_config(page_title="ETF Backfill Portfolio Visualizer", layout="wide")

# =============================
# Data & Mapping Layer
# =============================
@dataclass
class ProxySpec:
    source: str   # "YF"(Yahoo) | "FRED"(not used directly in loader here)
    series: str   # Yahoo symbol (preferred in this app)
    name: str
    transform: str = "identity"

# Base proxy map â€” include troublesome ones (IAU/BCI) mapped to Yahoo-loadable proxies
BASE_PROXY_MAP: Dict[str, ProxySpec] = {
    # Stocks / Bonds examples
    "QQQ":  ProxySpec("YF", "^NDX", "NASDAQ-100 Index"),
    "SPY":  ProxySpec("YF", "^GSPC", "S&P 500 Index"),
    "VTI":  ProxySpec("YF", "VTI", "Total U.S. Stock (ETF proxy)"),
    "VEA":  ProxySpec("YF", "VEA", "Dev ex-US (ETF proxy)"),
    "VWO":  ProxySpec("YF", "VWO", "EM Equities (ETF proxy)"),
    "VNQ":  ProxySpec("YF", "VNQ", "U.S. REITs (ETF proxy)"),
    "IEF":  ProxySpec("YF", "IEF", "U.S. Treasury 7-10y (ETF proxy)"),
    "VGLT": ProxySpec("YF", "VGLT", "U.S. Treasury Long (ETF proxy)"),
    "BND":  ProxySpec("YF", "AGG", "U.S. Aggregate (AGG as proxy)"),
    "AGG":  ProxySpec("YF", "AGG", "U.S. Aggregate Bonds"),
    "BIL":  ProxySpec("YF", "BIL", "1-3M T-Bill"),
    # Commodities & Gold
    "IAU":  ProxySpec("YF", "GLD",     "Gold proxy via GLD"),
    "GLD":  ProxySpec("YF", "GLD",     "Gold proxy via GLD"),
    "IAU.M":ProxySpec("YF", "GLD",     "Gold proxy via GLD"),
    "IAUUSD":ProxySpec("YF", "XAUUSD=X","Spot Gold USD"),
    "DBC":  ProxySpec("YF", "DBC",     "Broad Commodities (ETF)"),
    "BCI":  ProxySpec("YF", "^SPGSCI", "S&P GSCI Index (broad commodity)"),
}

# Lightweight yfinance helpers
@st.cache_data(show_spinner=False)
def yf_download(symbol: str, start: str = "1970-01-01", end: Optional[str] = None, auto_adjust: bool = True) -> pd.Series:
    import yfinance as yf
    df = yf.download(symbol, start=start, end=end, progress=False, auto_adjust=auto_adjust)
    if df.empty:
        return pd.Series(dtype=float, name=symbol)
    col = "Adj Close" if "Adj Close" in df.columns else "Close"
    s = df[col].dropna()
    s.name = symbol
    return s

@st.cache_data(show_spinner=False)
def yf_info(ticker: str) -> dict:
    try:
        import yfinance as yf
        t = yf.Ticker(ticker)
        info = t.info or {}
        return {
            "longName": info.get("longName"),
            "shortName": info.get("shortName"),
            "underlyingIndex": info.get("underlyingIndex"),
            "category": info.get("category"),
            "fundFamily": info.get("fundFamily"),
        }
    except Exception:
        return {}

# Rules to guess proxies from metadata text
_RULES: List[Tuple[re.Pattern, ProxySpec]] = [
    (re.compile(r"gold|ê¸ˆ", re.I), ProxySpec("YF", "GLD", "Gold proxy via GLD")),
    (re.compile(r"commodity|ì›ìì¬|gsci|bcom", re.I), ProxySpec("YF", "^SPGSCI", "S&P GSCI Index")),
    (re.compile(r"nasdaq.*100", re.I), ProxySpec("YF", "^NDX", "NASDAQ-100")),
    (re.compile(r"s&p.*500|sp\s*500", re.I), ProxySpec("YF", "^GSPC", "S&P 500")),
    (re.compile(r"7\-10|intermediate.*treasury|ì¤‘ê¸°êµ­ì±„", re.I), ProxySpec("YF", "IEF", "U.S. Treasury 7-10y")),
    (re.compile(r"tips|ë¬¼ê°€ì—°ë™", re.I), ProxySpec("YF", "TIP", "U.S. TIPS (ETF)")),
    (re.compile(r"reit|ë¦¬ì¸ ", re.I), ProxySpec("YF", "VNQ", "U.S. REITs (ETF)")),
]

@st.cache_data(show_spinner=False)
def audit_and_autofix_proxies(etfs: List[str], base_map: Dict[str, ProxySpec]) -> Tuple[pd.DataFrame, Dict[str, ProxySpec]]:
    pmap = dict(base_map)
    rows = []
    for t in etfs:
        key = t.upper().strip()
        if key in pmap:
            rows.append({"í‹°ì»¤": key, "ìƒíƒœ": "OK", "ì œì•ˆ": f"{pmap[key].source}:{pmap[key].series}"})
            continue
        info = yf_info(key)
        text = " ".join([str(v) for v in info.values() if v]).lower()
        suggestion = None
        for pat, spec in _RULES:
            if pat.search(text) or pat.search(key):
                suggestion = spec
                break
        if suggestion is not None:
            pmap[key] = suggestion
            rows.append({"í‹°ì»¤": key, "ìƒíƒœ": "AUTO_MAPPED", "ì œì•ˆ": f"{suggestion.source}:{suggestion.series}"})
        else:
            rows.append({"í‹°ì»¤": key, "ìƒíƒœ": "NEEDS_MANUAL", "ì œì•ˆ": "(ì—†ìŒ)"})
    return pd.DataFrame(rows), pmap

# Resolve a proxy ticker to load with Yahoo
def resolve_proxy_ticker(ticker: str, proxy_map: Dict[str, ProxySpec]) -> str:
    t = ticker.upper().strip()
    spec = proxy_map.get(t)
    if spec:
        return spec.series
    if t in {"IAU", "GLD"}: return "GLD"
    if t in {"BCI", "DBC"}: return "^SPGSCI"
    return ""

# Hybrid builder (ETF + Proxy splice)
def build_hybrid_series_from_proxy(etf_ticker: str, proxy_ticker: str, start: str = "1970-01-01") -> pd.Series:
    if not proxy_ticker:
        s_etf = yf_download(etf_ticker, start=start)
        s_etf.name = f"HYBRID_{etf_ticker}"
        return s_etf
    s_etf = yf_download(etf_ticker, start=start)
    s_proxy = yf_download(proxy_ticker, start=start)
    if s_etf.empty and s_proxy.empty:
        return pd.Series(dtype=float, name=f"HYBRID_{etf_ticker}")
    idx = pd.date_range(
        start=min([x.index.min() for x in [s_etf, s_proxy] if not x.empty]),
        end=max([x.index.max() for x in [s_etf, s_proxy] if not x.empty]),
        freq="B",
    )
    e = s_etf.reindex(idx).ffill()
    p = s_proxy.reindex(idx).ffill()
    overlap = pd.concat([e, p], axis=1).dropna()
    if overlap.empty:
        scaled_p = p
    else:
        x = overlap.iloc[:, 1].values
        y = overlap.iloc[:, 0].values
        denom = float(x @ x) if np.isfinite(x @ x) and (x @ x) != 0 else 1.0
        a = float((x @ y) / denom)
        scaled_p = p * a
    cutoff = e.first_valid_index()
    hybrid = scaled_p.copy()
    if cutoff is not None:
        hybrid.loc[cutoff:] = e.loc[cutoff:]
    hybrid.name = f"HYBRID_{etf_ticker}"
    return hybrid.dropna()

# Simple metrics
def to_monthly(s: pd.Series) -> pd.Series:
    return s.resample("M").last()

def perf_metrics(series: pd.Series) -> dict:
    if series.empty:
        return {"CAGR": np.nan, "Vol": np.nan, "MDD": np.nan}
    idx = series / series.iloc[0] * 100.0
    m = to_monthly(idx)
    rets = m.pct_change().dropna()
    years = (m.index[-1] - m.index[0]).days / 365.25
    cagr = (m.iloc[-1] / m.iloc[0]) ** (1/years) - 1 if years > 0 else np.nan
    vol = rets.std() * math.sqrt(12)
    roll_max = idx.cummax()
    dd = idx / roll_max - 1
    mdd = dd.min()
    return {"CAGR": cagr, "Vol": vol, "MDD": mdd}

# =============================
# UI helpers (Intro/Presets; Result)
# =============================
def render_intro():
    st.title("ETF ë°±í•„ í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì£¼ì–¼ë¼ì´ì €")
    st.caption("ETF ìƒì¥ ì „ ê¸°ê°„ê¹Œì§€ ì¶”ì¢…ì§€ìˆ˜ë¡œ ë°±í…ŒìŠ¤íŠ¸í•˜ëŠ” ì›¹ì•±ì…ë‹ˆë‹¤. (ê¸°ê°„: ìë™ ìµœëŒ€)")
    st.markdown("---")
    left, right = st.columns([1.2, 1])
    with left:
        st.subheader("ğŸ§­ ì²˜ìŒ ì˜¤ì…¨ë‚˜ìš”?")
        st.write(
            """
            ì´ ì›¹ì•±ì€ **ETF ìƒì¥ ì´ì „ êµ¬ê°„ê¹Œì§€** ì§€ìˆ˜/í”„ë¡ì‹œë¥¼ í™œìš©í•´ **í•˜ì´ë¸Œë¦¬ë“œ ì‹œë¦¬ì¦ˆ**ë¥¼ ë§Œë“¤ê³ ,
            í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ë¥¼ ì‰½ê²Œ ë¹„êµí•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.

            - **ë¶„ì‚°íˆ¬ì**: ì„œë¡œ ë‹¤ë¥¸ ìì‚°ì„ ì„ì–´ ìœ„í—˜ì„ ë‚®ì¶”ê³  ì•ˆì •ì  ì„±ê³¼ë¥¼ ì¶”êµ¬
            - **í•˜ì´ë¸Œë¦¬ë“œ ë°±í•„**: ìƒì¥ ì´ì „ì€ í”„ë¡ì‹œ ì§€ìˆ˜, ìƒì¥ ì´í›„ëŠ” ì‹¤ì œ ETFë¡œ ì´ì–´ë¶™ì´ê¸°
            - **ë¦¬ë°¸ëŸ°ì‹±**: ì •ê¸°ì ìœ¼ë¡œ ë¹„ì¤‘ ë³µì›(ì„ íƒ ì‚¬í•­)
            """
        )
    with right:
        st.info("Tip: ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ í‹°ì»¤ì™€ ë¹„ì¤‘ì„ ì…ë ¥í•˜ê³  â€˜ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰â€™ì„ ëˆŒëŸ¬ë³´ì„¸ìš”.")
    st.markdown("---")

def render_featured_portfolios():
    PRESETS = {
        "60:40 í¬íŠ¸í´ë¦¬ì˜¤": {
            "desc": "ì„±ì¥(ì£¼ì‹)+ì•ˆì •(ì±„ê¶Œ)ì˜ ê¸°ë³¸í˜•",
            "composition": [
                {"í‹°ì»¤": "SPY", "ìì‚°": "ë¯¸êµ­ ì£¼ì‹", "ë¹„ì¤‘(%)": 60},
                {"í‹°ì»¤": "BND", "ìì‚°": "ë¯¸êµ­ ì¢…í•©ì±„ê¶Œ", "ë¹„ì¤‘(%)": 40},
            ],
        },
        "ì˜¬ì›¨ë” í¬íŠ¸í´ë¦¬ì˜¤": {
            "desc": "ë ˆì´ ë‹¬ë¦¬ì˜¤ì‹ ë¦¬ìŠ¤í¬ ê· í˜•",
            "composition": [
                {"í‹°ì»¤": "VTI",  "ìì‚°": "ë¯¸êµ­ ì£¼ì‹",       "ë¹„ì¤‘(%)": 30},
                {"í‹°ì»¤": "VGLT", "ìì‚°": "ë¯¸êµ­ ì¥ê¸°êµ­ì±„",   "ë¹„ì¤‘(%)": 40},
                {"í‹°ì»¤": "IEF",  "ìì‚°": "ë¯¸êµ­ ì¤‘ê¸°êµ­ì±„",   "ë¹„ì¤‘(%)": 15},
                {"í‹°ì»¤": "IAU",  "ìì‚°": "ê¸ˆ",           "ë¹„ì¤‘(%)": 7.5},
                {"í‹°ì»¤": "DBC",  "ìì‚°": "ì›ìì¬",       "ë¹„ì¤‘(%)": 7.5},
            ],
        },
        "GAA í¬íŠ¸í´ë¦¬ì˜¤": {
            "desc": "ê¸€ë¡œë²Œ ê´‘ë²”ìœ„ ë¶„ì‚°",
            "composition": [
                {"í‹°ì»¤": "VTI", "ìì‚°": "ë¯¸êµ­ ì£¼ì‹",          "ë¹„ì¤‘(%)": 10},
                {"í‹°ì»¤": "VEA", "ìì‚°": "ì„ ì§„êµ­(ë¯¸êµ­ ì œì™¸) ì£¼ì‹", "ë¹„ì¤‘(%)": 10},
                {"í‹°ì»¤": "VWO", "ìì‚°": "ì‹ í¥êµ­ ì£¼ì‹",        "ë¹„ì¤‘(%)": 10},
                {"í‹°ì»¤": "VNQ", "ìì‚°": "REITs",            "ë¹„ì¤‘(%)": 10},
                {"í‹°ì»¤": "BND", "ìì‚°": "ë¯¸êµ­ ì¢…í•©ì±„ê¶Œ",      "ë¹„ì¤‘(%)": 20},
                {"í‹°ì»¤": "IEF", "ìì‚°": "ë¯¸êµ­ ì¤‘ê¸°êµ­ì±„",      "ë¹„ì¤‘(%)": 10},
                {"í‹°ì»¤": "IAU", "ìì‚°": "ê¸ˆ",               "ë¹„ì¤‘(%)": 10},
                {"í‹°ì»¤": "DBC", "ìì‚°": "ì›ìì¬",           "ë¹„ì¤‘(%)": 10},
                {"í‹°ì»¤": "BIL", "ìì‚°": "í˜„ê¸ˆ/ë‹¨ê¸°êµ­ì±„",     "ë¹„ì¤‘(%)": 10},
            ],
        },
    }

    st.subheader("ğŸš€ ëŒ€í‘œ í¬íŠ¸í´ë¦¬ì˜¤ ë¹„êµ & ë¹ ë¥¸ ë¶ˆëŸ¬ì˜¤ê¸°")
    for i, (name, spec) in enumerate(PRESETS.items()):
        st.markdown(f"#### ğŸ“Š {name}")
        st.caption(spec.get("desc", ""))
        dfc = pd.DataFrame(spec["composition"])
        c1, c2 = st.columns([1.2, 1])
        with c1:
            st.dataframe(dfc, hide_index=True, use_container_width=True)
            if st.button(f"ì´ êµ¬ì„± ë¶ˆëŸ¬ì˜¤ê¸°", key=f"load_{i}"):
                # ì‚¬ì´ë“œë°” ë°ì´í„°ì— ì¦‰ì‹œ ë°˜ì˜
                new_df = pd.DataFrame({
                    "í‹°ì»¤": dfc["í‹°ì»¤"].astype(str).str.upper().str.strip().tolist(),
                    "ë¹„ìœ¨ (%)": [float(x) for x in dfc["ë¹„ì¤‘(%)"].tolist()],
                })
                st.session_state["portfolio_rows"] = new_df
            
                # (ì„ íƒ) ê³¼ê±° ë°©ì‹ì˜ presetë„ ìœ ì§€í•˜ê³  ì‹¶ë‹¤ë©´ ë‚¨ê²¨ë‘¬ë„ ë¨
                st.session_state["preset_portfolio"] = {
                    "assets": new_df["í‹°ì»¤"].tolist(),
                    "labels": dfc["ìì‚°"].tolist(),
                    "weights": new_df["ë¹„ìœ¨ (%)"].tolist(),
                }
            
                st.success(f"â€˜{name}â€™ êµ¬ì„±ì„ ì‚¬ì´ë“œë°”ì— ë°˜ì˜í–ˆìŠµë‹ˆë‹¤.")
                st.rerun()  # ì¦‰ì‹œ ë¦¬ëŸ°í•´ì„œ ë°ì´í„°ì—ë””í„°ì— í‘œì‹œ

        with c2:
            sizes = dfc["ë¹„ì¤‘(%)"].astype(float).tolist()
            labels = (dfc["ìì‚°"] + " (" + dfc["ë¹„ì¤‘(%)"].astype(str) + "%)").tolist()
            fig, ax = plt.subplots()
            ax.pie(sizes, labels=labels, autopct='%1.0f%%', startangle=90)
            ax.axis('equal')
            st.pyplot(fig)
        st.markdown("---")

def render_results(port_series: Optional[pd.Series], metrics: Optional[dict]):
    st.subheader("í¬íŠ¸í´ë¦¬ì˜¤ ì§€ìˆ˜ (=100 ê¸°ì¤€)")
    if port_series is None or port_series.empty:
        st.warning("í‘œì‹œí•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    st.line_chart(port_series)
    if metrics:
        st.markdown(
            f"**CAGR:** {metrics['CAGR']*100:,.2f}%  |  **ë³€ë™ì„±:** {metrics['Vol']*100:,.2f}%  |  **ìµœëŒ€ë‚™í­:** {metrics['MDD']*100:,.2f}%"
        )

# =============================
# Sidebar â€” Portfolio Editor
# =============================
st.sidebar.header("1) í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±")

def _empty_rows(n=4):
    return pd.DataFrame({"í‹°ì»¤": ["" for _ in range(n)], "ë¹„ìœ¨ (%)": [0.0 for _ in range(n)]})

if "portfolio_rows" not in st.session_state:
    if "preset_portfolio" in st.session_state:
        p = st.session_state["preset_portfolio"]
        st.session_state["portfolio_rows"] = pd.DataFrame({
            "í‹°ì»¤": p.get("assets", []),
            "ë¹„ìœ¨ (%)": p.get("weights", []),
        })
    else:
        st.session_state["portfolio_rows"] = _empty_rows()

# Result-first state flags
if "backtest_started" not in st.session_state:
    st.session_state.backtest_started = False
if "port_series" not in st.session_state:
    st.session_state.port_series = None
if "port_metrics" not in st.session_state:
    st.session_state.port_metrics = None

# Ensure a few empty rows
base_df = st.session_state["portfolio_rows"]
if len(base_df) < 6:
    base_df = pd.concat([base_df, _empty_rows(6 - len(base_df))], ignore_index=True)

# Build auto mapping table from current tickers
def build_proxy_table_with_autofix(df_in: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, ProxySpec]]:
    tickers = [t for t in df_in["í‹°ì»¤"].astype(str).str.upper().str.strip().tolist() if t]
    report, pmap = audit_and_autofix_proxies(tickers, BASE_PROXY_MAP)
    rows = []
    for t in tickers:
        spec = pmap.get(t)
        label = "ì•Œ ìˆ˜ ì—†ìŒ"
        proxy = ""
        if spec:
            proxy = spec.series
            label = f"{spec.name} / proxy: {proxy}"
        elif t in {"IAU", "GLD"}:
            proxy = "GLD"; label = f"Gold proxy via GLD / proxy: {proxy}"
        elif t in {"BCI", "DBC"}:
            proxy = "^SPGSCI"; label = f"S&P GSCI Index / proxy: {proxy}"
        rows.append({"ETF": t, "Label": label, "Proxy": proxy})
    return pd.DataFrame(rows), pmap

proxy_table, proxy_map = build_proxy_table_with_autofix(base_df)

def _append_total_row(df: pd.DataFrame) -> pd.DataFrame:
    d = df.copy()
    total = float(pd.to_numeric(d["ë¹„ìœ¨ (%)"], errors="coerce").fillna(0).sum())
    d = pd.concat([d, pd.DataFrame({"í‹°ì»¤": ["í•©ê³„"], "ë¹„ìœ¨ (%)": [total]})], ignore_index=True)
    return d

editor_df = _append_total_row(base_df)

label_map = {r.ETF: r.Label for _, r in proxy_table.iterrows()}

def _label_for(t):
    t = str(t).upper().strip()
    if t == "í•©ê³„": return "â€”"
    return label_map.get(t, "ì•Œ ìˆ˜ ì—†ìŒ")

editor_df["ì¶”ì¢…ì§€ìˆ˜(ìë™)"] = editor_df["í‹°ì»¤"].apply(_label_for)

edited_df_out = st.sidebar.data_editor(
    editor_df,
    num_rows="dynamic",
    use_container_width=True,
    key="portfolio_editor",
    column_config={
        "í‹°ì»¤": st.column_config.TextColumn("í‹°ì»¤", help="ì˜ˆ: QQQ, IEF, IAU, BCI"),
        "ë¹„ìœ¨ (%)": st.column_config.NumberColumn("ë¹„ìœ¨ (%)", min_value=0.0, max_value=100.0, step=0.5, format="%.1f %%"),
        "ì¶”ì¢…ì§€ìˆ˜(ìë™)": st.column_config.TextColumn("ì¶”ì¢…ì§€ìˆ˜(ìë™)", help="ìë™ ë§¤í•‘ ë¼ë²¨", disabled=True),
    },
    disabled=["ì¶”ì¢…ì§€ìˆ˜(ìë™)"],
)

# Save back (drop total row)
st.session_state["portfolio_rows"] = edited_df_out.iloc[:-1][["í‹°ì»¤", "ë¹„ìœ¨ (%)"]]

st.sidebar.header("2) ê¸°ê°„ ì„¤ì •")
colA, colB = st.sidebar.columns(2)
with colA:
    start_date = st.date_input("ì‹œì‘ì¼", value=date(1990,1,1))
with colB:
    end_date = st.date_input("ì¢…ë£Œì¼", value=date.today())

run_bt = st.sidebar.button("ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰", type="primary")
reset_bt = st.sidebar.button("ì´ˆê¸°í™”(ì²˜ìŒ í™”ë©´ìœ¼ë¡œ)", type="secondary")

if reset_bt:
    st.session_state.backtest_started = False
    st.session_state.port_series = None
    st.session_state.port_metrics = None

# =============================
# Backtest Execution
# =============================
main_tab1, main_tab2 = st.tabs(["ğŸ“ˆ ê²°ê³¼", "ğŸ§ª ë§¤í•‘ ë¦¬í¬íŠ¸"])

if run_bt:
    with st.spinner("ë°ì´í„° ë¡œë”© ë° ë°±í…ŒìŠ¤íŠ¸ ì¤‘..."):
        dfp = st.session_state["portfolio_rows"].copy()
        # Clean rows
        dfp["í‹°ì»¤"] = dfp["í‹°ì»¤"].astype(str).str.upper().str.strip()
        dfp["ë¹„ìœ¨ (%)"] = pd.to_numeric(dfp["ë¹„ìœ¨ (%)"], errors="coerce").fillna(0.0)
        dfp = dfp[dfp["í‹°ì»¤"] != ""]
        dfp = dfp[dfp["ë¹„ìœ¨ (%)"] > 0]
        if dfp.empty:
            st.error("í¬íŠ¸í´ë¦¬ì˜¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. í‹°ì»¤ì™€ ë¹„ì¤‘ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            weights = dfp["ë¹„ìœ¨ (%)"].values
            if weights.sum() == 0:
                st.error("ë¹„ì¤‘ í•©ê³„ê°€ 0ì…ë‹ˆë‹¤. ë¹„ì¤‘ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                weights = weights / weights.sum()
                # Build each hybrid series
                series_map = {}
                for t, w in zip(dfp["í‹°ì»¤"].tolist(), weights.tolist()):
                    proxy_sym = resolve_proxy_ticker(t, proxy_map)
                    hy = build_hybrid_series_from_proxy(t, proxy_sym, start=start_date.isoformat())
                    series_map[t] = hy
                # Align & combine
                all_idx = None
                for s in series_map.values():
                    if all_idx is None:
                        all_idx = s.index
                    else:
                        all_idx = all_idx.union(s.index)
                all_idx = pd.DatetimeIndex(sorted(all_idx))
                parts = []
                for t, w in zip(dfp["í‹°ì»¤"].tolist(), weights.tolist()):
                    s = series_map[t].reindex(all_idx).ffill()
                    s = s / s.iloc[0] * 100.0
                    parts.append(s * w)
                port = pd.concat(parts, axis=1).sum(axis=1).dropna()
                port = port.loc[(port.index >= pd.to_datetime(start_date)) & (port.index <= pd.to_datetime(end_date))]
                m = perf_metrics(port)

                # Save to state for result-first rendering
                st.session_state.backtest_started = True
                st.session_state.port_series = port
                st.session_state.port_metrics = m

    # Show mapping report after run
    with main_tab2:
        rep, _ = audit_and_autofix_proxies(dfp["í‹°ì»¤"].tolist(), BASE_PROXY_MAP)
        st.dataframe(rep, use_container_width=True)

# =============================
# Result-first / Intro visibility control
# =============================
# =============================
# Result-first / Intro visibility control
# =============================
if st.session_state.backtest_started:
    # âœ… ê²°ê³¼ë¥¼ ìµœìƒë‹¨ì— ë¨¼ì € í‘œì‹œ
    with main_tab1:
        render_results(st.session_state.port_series, st.session_state.port_metrics)

    # âœ… ì‹¤í–‰ í›„: í† ê¸€ì€ 'ëŒ€í‘œ í¬íŠ¸í´ë¦¬ì˜¤'ë§Œ í‘œì‹œ (ì´ˆê¸° ì•ˆë‚´ëŠ” ì œì™¸)
    st.toggle("ëŒ€í‘œ í¬íŠ¸í´ë¦¬ì˜¤ ë³´ê¸°", value=False, key="show_presets_after_run")
    if st.session_state.get("show_presets_after_run"):
        render_featured_portfolios()
else:
    # âœ… ì•„ì§ ì‹¤í–‰ ì „: (ê¸°ì¡´ ê·¸ëŒ€ë¡œ) ì•ˆë‚´ + ëŒ€í‘œ í¬íŠ¸í´ë¦¬ì˜¤ ë…¸ì¶œ
    render_intro()
    render_featured_portfolios()
    with main_tab1:
        st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ì…ë ¥í•˜ê³  â€˜ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰â€™ì„ ëˆŒëŸ¬ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    with main_tab2:
        st.dataframe(proxy_table, use_container_width=True)

st.markdown("---")
st.caption("â“˜ ì°¸ê³ : IAU/BCI ë“± ì¼ë¶€ ETFëŠ” ê³µì‹ 'ì§€ìˆ˜'ê°€ ê³µê°œ í‘œì¤€í™”ë˜ì–´ ìˆì§€ ì•Šì•„, Yahooì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œ ëŒ€ì²´ í”„ë¡ì‹œ(GLD, ^SPGSCI ë“±)ë¡œ ìë™ ë§¤í•‘í•©ë‹ˆë‹¤. ë” ì •êµí•œ ì§€ìˆ˜(ì˜ˆ: BCOMTR)ë¥¼ ì“°ë ¤ë©´ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")


